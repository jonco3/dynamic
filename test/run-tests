#!/usr/bin/env python3

import argparse
import os
import re
import subprocess
import sys
import time

parser = argparse.ArgumentParser(description='Run tests.')
parser.add_argument('--verbose', action='store_true',
                    help = 'Print failure information')
parser.add_argument('--benchmark', action='store_true',
                    help = 'Output time take to run tests')
parser.add_argument('--dir', metavar='TEST_DIR', action='append', dest='dirs',
                    help='directory containing tests to run')
parser.add_argument('--command', metavar='CMD', action='append', dest='commands',
                    help='python interpreter command')
args = parser.parse_args()

if not args.commands:
    sys.exit("No commands to test")

if not args.dirs:
    sys.exit("No test directories")

runCount = 0
passCount = 0

def runTest(filename, command):
    global runCount, passCount
    runCount += 1

    command = command.split() + [filename]
    expect = []

    with open(filename) as f:
        while True:
            line = f.readline().rstrip()
            match = re.match('# ([\w-]+): (.*)$', line)
            if not match:
                break

            key, value = match.groups()
            if key == 'output':
                expect.append(value)
            elif key == 'args':
                if not args.benchmark:
                    command.extend(value.split())
            elif key == 'bench-args':
                if args.benchmark:
                    command.extend(value.split())
            else:
                return 'BAD', 'Error parsing header option: ' + key

    if not expect:
        return 'BAD', 'No expected output header'

    ok = True
    startTime = time.perf_counter()
    try:
        output = subprocess.check_output(command, stderr = subprocess.STDOUT)
        endTime = time.perf_counter()
    except subprocess.CalledProcessError as e:
        ok = False
        output = e.output

    output = output.decode().strip()

    if not ok:
        return 'FAIL', 'Execution failed: ' + output

    if not args.benchmark:
        output = output.strip()
        if output != "\n".join(expect):
            message = ('    Output did not match expected:\n' +
                       '      Expected: ' + '|'.join(expect) + '\n' +
                       '      Actual:   ' + output.replace('\n', '|'))
            return 'FAIL', message

    passCount += 1
    return 'PASS', endTime - startTime

def formatTime(secs):
    return "%-20.2f" % (secs * 1000)

def formatResult(result):
    return "%-20s" % result

def runTestDir(dirname, names):
    for name in names:
        if name.endswith('.py'):
            filename = os.path.join(dirname, name)
            results = list(map(lambda c: runTest(filename, c), args.commands))
            line = '  %-20s ' % name
            for result, extra in results:
                if result != 'PASS':
                    line += formatResult(result)
                elif args.benchmark:
                    line += formatTime(extra)
                else:
                    line += formatResult("ok")
            print(line)

            if args.verbose:
                for result, extra in results:
                    if result != 'PASS':
                        print(extra)

line = 'Running tests:         '
line += "".join(map(lambda c: formatResult(c.split()[0]), args.commands))
print(line)

for testDir in args.dirs:
    for dirpath, dirnames, filenames in os.walk(testDir):
        runTestDir(dirpath, filenames)
print("%d tests passed out of %d" % (passCount, runCount))
if passCount != runCount:
    sys.exit(1)
